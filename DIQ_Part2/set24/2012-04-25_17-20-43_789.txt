a*	IEEE TRANSACTIONS ON nOOOTJCS AMD AUTOMATON* VOL. SO- JUNE MM
Segmentation via Manipulation
Constantine J. Tsikos and Ruzena K. Bajcsy, Senior Member, IEEE
Abstract—"tot iHrMact the paradif m nf iterate. interactive wn segmentation and simplification nf ruMa of un torn objects via vUn and maaipalation Tic mi simptift-catioa »	on ike graph opemdnas of mtn and dp
wwil These ontKIom are mbd isomorphic to the pkrk paste manipafcticHi actions. We net the imn at graph generators *»d the manipalator m the decomposing ■ nhiiliai at tie graph*. The model b a aoadeterminbtic IM< state Taring Machine. We integrated a vision system, a ■atl»B»alir. and force torqve and other sensory input into a robot wort cafl and conducted experiments to test convergence and arm recovery of low different strategies. We fomd that «Mn certain cen#dna< the mitefiti can tolerate errors ha the tnwry date, recover from patMogkai states, and coaverfe.
I. bmoDucnoN
The iootivttioD for this paper it the obnnitiot that i scene containing move than one object moM of the time cannot be segmented only by vision or in general by any noncontact sensing method. Visual information may ba stf ficient to accurately segment simple objects and nonovertep-ptag scenes, However, in general, u is net sufficient for random heaps of unknown objects.
If no a pnori knowledge is available, the vision system cannot reliably distinguish between overlaps caused by two different objects in the scene and overlaps caused by a single self-occluding object A flat rigid object supported by and totally occluding another smaller object may be recognized as a large boa-shaped object. Similarly, a Am nonrigtd object supported in the middle by a smaller object may be recognized as convex, while if it it supported at the edges by more than one object, it may be recognized at concave.
Therefore, machine vision alone (or any noncontact sensing method) is not sufficient for segmentation and recognition. An exception to this may be the case when the objects are physically separated so that the noncontact sensor can measure this separation or one knows a priori a great deal about the objects (their geometry, material, etc.).
Mamscnpt received March 24, !9t9. revised January 1.1990. This work «a supported by the U..S, Ptotal Service BOA under Contract 10*130-87-H-0001 /M-0195: by the U.S. Air Force under Great AFOSR F49620-S5-K-001S; by the U.S. Army under Grant DAAG-2*S4-K-0061; by the National Science Fmiarfcrwm under Gnats CER/DCRI2-19I96 Ao2, INTtS-14199, DMCtS-17315; by NASA under Great NAOS-1045. by the ON* under Grant SB-J5923-0; by the NIH under Grants NS-10939-11 (as pan of the Cerabro Vascular Reeeaich Center) aad 1-R01-NS-23636-QU by ARPA under Grant N0014-U-K-0632. by NATO under Grant 0024/15, and by the DEC Corporation. IBM. and the LORD Corporation
C. 1. Tsfltoe was with the Department of Computer and Information Science. University of Pennsylvania. Philadelphia. PA 19104-63S9 He is now with the Siemens Corporate Research Laboratories. Princeton, N1 08540,
R. R. Bajcsy is with the Department of Computer and Information Science. University of Pennsylvania. Philadelphia. PA 19104-6389
IEEE Log Number 9142996.
The traditional approach ia to ttgmrnf the noncontact sensory information (range, intensity, etc.) regardless of scene coaopkxity. Then, baaed on the outcome of segmentation. to interpret the scene and recognize the objects. The problem with this approach is that reliability decreases when scenes become more complex and when m priori assumptions arc removed.
On approach ts different Instead of trying to deal with an ever hk rrating nwi acene complexity, we use the manipulator to anafcr the scene sampler lor the vision system. Oar paradigm la analogont to ha»mg the band help the eye when interpretation of vtanal information is ambiguous, or when the scene it vfcnaBy itompk a
Our systaaa Is iterative bccantc inarinm arraagements o4 objects lorsa layers Dtae to oar m.i'f—1act teaser arrangement, oaiy the top layer of it heap a viable at any given tame aaal the objects are iiammal from Che scene one at a tune Ka general, the sysaem aaaat tenia and mtnipulur more than otcc for every random scene
The sysmn ia interactive because the ntxa system may request a manipulatory action to teaolve an maerpretabon ambsgmry. to reduce vianal complexity, or to grasp and remove an object from the scene. The manipulatory action must be monitored by the notKmiart sensor (vision system) sa well at the contact sensors (force/torque) ia a dosed loop
A.	Assumptions
Our assumptions ate:
1)	The scene is teachable by the manipulator aad accessible to the sensors, i.e.. the entire scene it visible, although occlusions may occur.
2)	The acene ts decomposable, it consists of convex objects held together by the forces of gravity and frictioo.
3)	The objects may or may not be rigid. Their size and weight is such that they are manipulate with a suitable end effector. The complexity of the scene is bounded, i.e.. typical scenes are three to six layers deep and may contain 15 to 30 objects.
4)	There is a well defined goal state that is detectable by the available sensors. The goal may be an empty scene or an organized/ordered scene.
B.	Domain
The domain is the class of irregular parcels and pieces (IPP) found in a post office environment. The class consists of rigid and nonrigid flats, boxes, tubes, and rolls. The objects have different weights, sizes, colors, visual surface textures (address labels, stamps, and other markings), varying porocity, coefficients of friction, and rigidity. Because many of these objects are not rigid, their true geometric shape cannot be measured; it is rather a function of where the
I042-296X/91AMXM3306S01.00 © 1991 IEEE