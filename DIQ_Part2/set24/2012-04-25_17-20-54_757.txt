IEEE TRANSACTIONS ON ROBOTICS AND AUTOMATION. VOL ?. NO 3. JUNE 1991
Segmentation via Manipulation
Constantino J. Tsikos and Ruzena K. Bajcsy, Senior Member, IEEE
Ahstmci Wi introduce the paradigm of Iterative, (attractive Mt«r stfmeatattoa and simplification of random iMips of unknown objects via vision and manipulation. The xtae stepHfi-cation b Kaard om the graph operations of vertex and edge removal. TWse operations are defined isomorphic to the pick and push maaipaiatioa actions. We ase the feasors as graph generators and the manipulator as the decomposing mechanism of the graphs. The model b a aoadetermiaistic finite-state Turing Machine. We Integrated a vision system, a manipulator, and force /torque and other sensory input into a robot work cell and conducted experiments to test convergence and error recovery of four different strategies. We found that under certain conditions the strategies can tolerate errors in the sensory data, recover from pathological states, and converge.
I. Introduction
THE motivation for this paper is the observation that a scene containing more than one object most of the time cannot be segmented only by vision or in general by any nracontact sensing method. Visual information may be sufficient to accurately segment simple objects and nonoverlap-ptng scenes However, in general, it is not sufficient for random heaps of unknown objects.
If no a prtori knowledge is available, the vision system cannot reliably distinguish between overlaps caused by two different objects in the scene and overlaps caused by a single self-occluding object. A flat rigid object supported by and totally occluding another smaller object may be recognized as a large box-shaped object. Similarly, a flat nonrigid object supported in the middle by a smaller object may be recognized as convex, while if it is supported at the edges by more than one object, it may be recognized as concave.
Therefore, machine vision alone (or any noncontact sensing method) is not sufficient for segmentation and recognition. An exception to this may be the case when the objects are physically separated so that the noncontact sensor can measure this separation or one knows a priori a great deal about the objects (their geometry, material, etc.).
M—wrry received Marc* 24, 19*9; revised January 1. 1990. Tfcfc work «« mpponed by *e US taral Scroce BOA under Contract 10C30-S7-H-0001 >4-01*5. by the U.S. Air Force trader Grua AFOSR F49C04S4C-001S; by *c U.S. Army under Qrmt DAAG-2*S4 k-OOM. by the National Scmce Fotradtfx* uafer Grants CE*/DCRtM91% Ao3, INTSS-MlW. DMC1M7315. by NASA trader Oral NAGS-I04S; by the ONR wafer Oram SI-KIM. by she NTH aafer Grrato N*tO»SMl (at pert of the Carabro Vascular Reeearcfc Carter) art 1-R01-NS-236K-01. by ARPA trader Grant NOOK-SS R by NATO ante Grant 0094/SS. tad by the DEC Caifonm. IBM. aad the LOUD Ooepomxra
C I Token ana the Deyanawt of Cae^raer aad Woraam Soaaea. Umnety of fuaijl ■■« Made***. PA 19104439 He i» «aa fH ii Smomm Corporate Research I ifcirMwn, Nmca. KJ 0*540
t K Bepcsy m a* (Be Depanraeai of Computer mi tafcrmeataa Scraaee Uava»aa> af Hnnjh rail. rUMe^phea. tA I4t04~43t9
WE* U* Naaafca* ftC**
The traditional approach is to segment the noncontact sensory information (range, intensity, etc.) regardless of scene complexity. Then, based on the outcome of segmentation, to interpret the scene and recognize the objects. The problem with this approach is that reliability decreases when scenes become more complex and when a priori assumptions are removed.
Our approach is different. Instead of trying to deal with an ever increasing visual scene complexity, we use the manipulator to make the scene simpler for the vision system. Our paradigm is analogous to having the hand help the eye when interpretation of visual information is ambiguous, or when the scene is visually complex.
Our system is iterative because random arrangements of objects form layers. Due to our noncontact sensor arrangement, only the top layer of the heap is visible at any given time and the objects are removed from the scene one at a time. In general, the system must sense and manipulate more than once for every random scene.
The system is interactive because the vision system may request a manipulatory action to resolve an interpretation ambiguity, to reduce visual complexity, or to grasp and remove an object from the scene. The manipulatory action must be monitored by the noncontact sensor (vision system) as well as the contact sensors (force/torque) in a closed loop.
A.	Assumptions
Our assumptions are:
1)	The scene is reachable by the manipulator and accessible to the sensors, i.e., the entire scene is visible, although occlusions may occur.
2)	The scene is decomposable; it consists of convex objects held together by the forces of gravity and friction.
3)	The objects may or may not be rigid. Their sixe and weight is such that they are manipulable with a suitable end effector. The complexity of the scene is bounded, i.e., typical scenes are three to six layers deep and may contain 15 to 30 objects.
4)	There is a well defined goal state that is detectable by the available sensors. The goal may be an empty scene or an organised/ordered scene.
B,	Domain
The domain is the class of irregular parcels and pieces (EPF) found in a post office environment. The class constats of rigid and nonrigid flats, boxes, tubes, aad rolls The objects have different weights, sizes, colors, visual surface textures (address labels, stamps, and other mariang*). varying porocity, coefficients of friction, and rigidity. Became many of these objects are not rigid, their trot geometric shape cannot be measured; tf ts rather a toncoon of where the
KK24MX*t*>ia(MB0890t 00 € 199! «B